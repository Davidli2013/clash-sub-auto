name: Auto Update HK SG JP Nodes

on:
  schedule:
    - cron: '0 8-23/2 * * *'  # æ¯2å°æ—¶è‡ªåŠ¨æ›´æ–°
  workflow_dispatch:

jobs:
  update-region-nodes:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install pyyaml requests

      - name: Download and filter nodes (æ‰©å¤§ç²—ç­›+ä¸¥æ ¼ç²¾ç­›)
        run: |
          python3 << 'EOF'
          import os
          import yaml
          import random
          import requests
          from typing import List, Dict

          # ========== æ ¸å¿ƒé…ç½® ==========
          CONFIG_FILE = "config.yaml"
          TIMEOUT = 15
          MIN_NODES = 30  # æ‰€æœ‰åœ°åŒºä¿åº•30ä¸ª
          LATENCY_THRESHOLD = 500  # ä¼˜è´¨èŠ‚ç‚¹é˜ˆå€¼ï¼šå»¶è¿Ÿ<500ms
          # å„åœ°åŒºæœ€å¤§èŠ‚ç‚¹æ•°é…ç½®
          MAX_NODES_CONFIG = {
              "hk": 100,  # é¦™æ¸¯ä¿ç•™100ä¸ª
              "sg": 30,   # æ–°åŠ å¡ä¿ç•™30ä¸ª
              "jp": 30    # æ—¥æœ¬ä¿ç•™30ä¸ª
          }
          # æ›¿æ¢ä¸ºä½ çš„Cloudflare Workeråœ°å€
          CF_WORKERS_API = "https://yellow-tree-130b.lijinlonghk666.workers.dev"

          # åœ°åŒºé…ç½®ï¼šæ‰©å¤§å…³é”®è¯ï¼Œæ‹‰å¤§æ’’ç½‘èŒƒå›´
          REGION_CONFIG = {
              "hk": {
                  "filename": "sub_hk.yaml",
                  # æ–°å¢æ›´å¤šé¦™æ¸¯å…³é”®è¯ï¼Œç¡®ä¿ç²—ç­›è¶³å¤Ÿå¤š
                  "keywords": ["hk", "hongkong", "é¦™æ¸¯", "HK", "HongKong", "HKT", "CN2", "æ²™ç”°", "èƒæ¹¾", "ä¸­ç¯", "ä¹é¾™"],
                  "prefix": "HK-"
              },
              "sg": {
                  "filename": "sub_sg.yaml",
                  # æ–°å¢æ–°åŠ å¡å…³é”®è¯
                  "keywords": ["sg", "singapore", "æ–°åŠ å¡", "SG", "Singapore", "SGD", "ç‹®åŸ", "æ–°åŠ å¡ğŸ‡¸ğŸ‡¬"],
                  "prefix": "SG-"
              },
              "jp": {
                  "filename": "sub_jp.yaml",
                  # æ–°å¢æ—¥æœ¬å…³é”®è¯
                  "keywords": ["jp", "japan", "æ—¥æœ¬", "JP", "Japan", "ä¸œäº¬", "å¤§é˜ª", "JPä¸œ", "JPè¥¿", "æ¨ªæ»¨", "åå¤å±‹"],
                  "prefix": "JP-"
              }
          }

          ALLOWED_PROTOCOLS = ["trojan", "vmess", "vless", "shadowsocks", "ssr"]

          class ProxyNode:
              def __init__(self, d, prefix):
                  self.name = f"{prefix}{d.get('name', f'Node{random.randint(1000,9999)}')}"
                  self.type = d.get("type", "")
                  self.server = d.get("server", "")
                  self.port = d.get("port", 443)
                  self.password = d.get("password", "")
                  self.sni = d.get("sni", "")
                  self.skip_cert_verify = d.get("skip-cert-verify", True)
                  self.udp = d.get("udp", True)
                  self.network = d.get("network", "tcp")
                  self.uuid = d.get("uuid", "")
                  self.cipher = d.get("cipher", "")
                  self.latency = 9999.0
                  self.available = False
                  self.high_quality = False  # æ ‡è®°æ˜¯å¦ä¸ºä¼˜è´¨èŠ‚ç‚¹ï¼ˆå»¶è¿Ÿ<500msï¼‰

              def to_dict(self):
                  b = {
                      "name": self.name,
                      "type": self.type,
                      "server": self.server,
                      "port": self.port,
                      "skip-cert-verify": self.skip_cert_verify,
                      "udp": self.udp
                  }
                  if self.type == "trojan":
                      b["password"] = self.password
                      if self.sni:
                          b["sni"] = self.sni
                  elif self.type in ["vmess", "vless"]:
                      b["uuid"] = self.uuid
                      if self.sni:
                          b["servername"] = self.sni
                  elif self.type in ["shadowsocks", "ssr"]:
                      b["password"] = self.password
                      b["cipher"] = self.cipher
                  if self.network != "tcp":
                      b["network"] = self.network
                  return b

              def get_unique_key(self):
                  return f"{self.type}_{self.server}_{self.port}_{self.password[:8]}"

              def test_latency_cf(self):
                  """è°ƒç”¨Cloudflare Workersæµ‹é€Ÿï¼ˆå†…åœ°è§†è§’ï¼‰"""
                  try:
                      resp = requests.post(
                          CF_WORKERS_API,
                          json={"server": self.server, "port": self.port},
                          timeout=TIMEOUT
                      )
                      if resp.status_code == 200:
                          self.latency = resp.json().get("latency", 9999.0)
                          self.available = self.latency < 9999  # å¯ç”¨ï¼šå»¶è¿Ÿä¸æ˜¯9999
                          self.high_quality = self.latency < LATENCY_THRESHOLD  # ä¼˜è´¨ï¼šå»¶è¿Ÿ<500ms
                  except Exception as e:
                      print(f"æµ‹é€Ÿå¤±è´¥ {self.name}: {e}")

          def load_existing_nodes(filename: str) -> List[ProxyNode]:
              existing_nodes = []
              if not os.path.exists(filename):
                  return existing_nodes
              try:
                  with open(filename, 'r', encoding='utf-8') as f:
                      config = yaml.safe_load(f)
                  if not config or "proxies" not in config:
                      return existing_nodes
                  for p in config["proxies"]:
                      if p.get("type") in ALLOWED_PROTOCOLS:
                          prefix = ""
                          for code, cfg in REGION_CONFIG.items():
                              if p["name"].startswith(cfg["prefix"]):
                                  prefix = cfg["prefix"]
                                  break
                          existing_nodes.append(ProxyNode(p, prefix))
              except Exception as e:
                  print(f"è¯»å–å†å²èŠ‚ç‚¹å¤±è´¥: {e}")
              return existing_nodes

          def load_subs():
              if not os.path.exists(CONFIG_FILE):
                  print(f"é…ç½®æ–‡ä»¶ {CONFIG_FILE} ä¸å­˜åœ¨ï¼")
                  return []
              with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                  return yaml.safe_load(f).get("subs", [])

          def get_content(url):
              try:
                  r = requests.get(url, timeout=TIMEOUT)
                  r.raise_for_status()
                  return r.text
              except Exception as e:
                  print(f"ä¸‹è½½è®¢é˜…å¤±è´¥ {url}: {e}")
                  return ""

          def parse_proxies(txt):
              try:
                  d = yaml.safe_load(txt)
                  if isinstance(d, dict) and "proxies" in d:
                      return d["proxies"]
                  elif isinstance(d, list):
                      return d
              except Exception as e:
                  print(f"è§£æèŠ‚ç‚¹å¤±è´¥: {e}")
              return []

          def filter_region(proxies, kws):
              """æ‰©å¤§ç²—ç­›èŒƒå›´ï¼šä¸é™åˆ¶æ•°é‡ï¼Œåªè¦åŒ¹é…å…³é”®è¯å°±ä¿ç•™"""
              res = []
              for p in proxies:
                  if not isinstance(p, dict):
                      continue
                  if p.get("type") not in ALLOWED_PROTOCOLS:
                      continue
                  n = str(p.get("name", "")).lower()
                  s = str(p.get("server", "")).lower()
                  # æ”¾å®½åŒ¹é…æ¡ä»¶ï¼šåªè¦å…³é”®è¯å‡ºç°åœ¨åå­—/æœåŠ¡å™¨é‡Œå°±ä¿ç•™
                  if any(kw.lower() in n or kw.lower() in s for kw in kws):
                      res.append(p)
              print(f"ç²—ç­›å‡º {len(res)} ä¸ªå€™é€‰èŠ‚ç‚¹")
              return res

          def merge_nodes(existing: List[ProxyNode], new: List[ProxyNode], max_nodes: int) -> List[ProxyNode]:
              """åˆå¹¶èŠ‚ç‚¹ï¼šä¼˜å…ˆä¼˜è´¨èŠ‚ç‚¹ + æŒ‰å»¶è¿Ÿæ’åº + ä¿åº•30ä¸ª"""
              node_dict = {n.get_unique_key(): n for n in existing}
              # æ·»åŠ æ–°èŠ‚ç‚¹ï¼ˆä¸é‡å¤ï¼‰
              for n in new:
                  key = n.get_unique_key()
                  if key not in node_dict:
                      node_dict[key] = n
              # æ‹†åˆ†èŠ‚ç‚¹ï¼šä¼˜è´¨èŠ‚ç‚¹ï¼ˆ<500msï¼‰ã€å¯ç”¨èŠ‚ç‚¹ï¼ˆâ‰¥500msï¼‰ã€ä¸å¯ç”¨èŠ‚ç‚¹
              all_nodes = list(node_dict.values())
              high_quality_nodes = [n for n in all_nodes if n.high_quality]
              normal_available_nodes = [n for n in all_nodes if n.available and not n.high_quality]
              unavailable_nodes = [n for n in all_nodes if not n.available]
              
              # æ’åºï¼šä¼˜è´¨èŠ‚ç‚¹ä¼˜å…ˆï¼ˆæŒ‰å»¶è¿Ÿå‡åºï¼‰â†’ æ™®é€šå¯ç”¨èŠ‚ç‚¹ï¼ˆæŒ‰å»¶è¿Ÿå‡åºï¼‰â†’ ä¸å¯ç”¨èŠ‚ç‚¹
              high_quality_nodes.sort(key=lambda x: x.latency)
              normal_available_nodes.sort(key=lambda x: x.latency)
              merged = high_quality_nodes + normal_available_nodes + unavailable_nodes
              
              # ä¿åº•é€»è¾‘ï¼šè‡³å°‘ä¿ç•™30ä¸ª
              current_count = len(merged)
              if current_count < MIN_NODES:
                  print(f"å¯ç”¨èŠ‚ç‚¹ä¸è¶³{MIN_NODES}ä¸ªï¼Œè¡¥å……ä¿åº•èŠ‚ç‚¹...")
                  need_add = MIN_NODES - current_count
                  for i in range(need_add):
                      dummy = ProxyNode({
                          "name": f"Backup_{random.randint(1000,9999)}",
                          "type": "trojan",
                          "server": f"backup{i}.example.com",
                          "port": 443,
                          "password": "dummy"
                      }, "HK-")
                      dummy.latency = 9999.0
                      merged.append(dummy)
              
              # æŒ‰åœ°åŒºé™åˆ¶æœ€å¤§èŠ‚ç‚¹æ•°ï¼Œä¼˜å…ˆä¿ç•™ä¼˜è´¨èŠ‚ç‚¹
              final_nodes = merged[:max_nodes]
              # ç»Ÿè®¡æœ€ç»ˆèŠ‚ç‚¹è´¨é‡
              final_high_quality = len([n for n in final_nodes if n.high_quality])
              final_available = len([n for n in final_nodes if n.available])
              print(f"ç²¾ç­›åï¼šä¼˜è´¨èŠ‚ç‚¹{final_high_quality}ä¸ªï¼Œå¯ç”¨èŠ‚ç‚¹{final_available}ä¸ªï¼Œæ€»è®¡{len(final_nodes)}ä¸ª")
              
              return final_nodes

          def make_config(nodes, region_name):
              # ä¼˜å…ˆç”¨å¯ç”¨èŠ‚ç‚¹ï¼Œæ— å¯ç”¨èŠ‚ç‚¹æ‰ç”¨ä¿åº•
              available_nodes = [n for n in nodes if n.available]
              if not available_nodes:
                  available_nodes = nodes[:MIN_NODES]
              
              names = [n.name for n in available_nodes]
              return {
                  "mixed-port": 7890,
                  "allow-lan": True,
                  "mode": "Rule",
                  "log-level": "info",
                  "external-controller": "127.0.0.1:9090",
                  "proxies": [n.to_dict() for n in available_nodes],
                  "proxy-groups": [
                      {
                          "name": f"{region_name} Auto",
                          "type": "url-test",
                          "proxies": names,
                          "url": "http://www.google.com/generate_204",
                          "interval": 300
                      },
                      {
                          "name": f"{region_name} Manual",
                          "type": "select",
                          "proxies": names + [f"{region_name} Auto", "DIRECT"]
                      }
                  ],
                  "rules": [
                      "GEOIP,CN,DIRECT",
                      f"MATCH,{region_name} Auto"
                  ]
              }

          def main():
              subs = load_subs()
              all_new_proxies = []
              for u in subs:
                  txt = get_content(u)
                  ps = parse_proxies(txt)
                  all_new_proxies.extend(ps)
              print(f"å…±ä»è®¢é˜…æºè·å– {len(all_new_proxies)} ä¸ªèŠ‚ç‚¹")

              for code, cfg in REGION_CONFIG.items():
                  print(f"\n===== å¤„ç† {code.upper()} èŠ‚ç‚¹ =====")
                  existing_nodes = load_existing_nodes(cfg["filename"])
                  print(f"å†å²èŠ‚ç‚¹æ•°: {len(existing_nodes)}")

                  # ç¬¬ä¸€æ­¥ï¼šç²—ç­›ï¼ˆæ‰©å¤§æ’’ç½‘èŒƒå›´ï¼‰
                  region_new_proxies = filter_region(all_new_proxies, cfg["keywords"])
                  new_nodes = [ProxyNode(p, cfg["prefix"]) for p in region_new_proxies]
                  
                  # ç¬¬äºŒæ­¥ï¼šç²¾ç­›ï¼ˆå†…åœ°æµ‹é€Ÿï¼‰
                  print("å¼€å§‹å†…åœ°è§†è§’æµ‹é€Ÿï¼ˆä¼˜å…ˆä¿ç•™å»¶è¿Ÿ<500msçš„ä¼˜è´¨èŠ‚ç‚¹ï¼‰...")
                  for i, n in enumerate(new_nodes):
                      print(f"æµ‹é€Ÿä¸­ {i+1}/{len(new_nodes)}: {n.name}")
                      n.test_latency_cf()
                      import time
                      time.sleep(0.2)

                  # ç¬¬ä¸‰æ­¥ï¼šåˆå¹¶+æŒ‰è´¨é‡æ’åº+é™åˆ¶æ•°é‡
                  max_nodes = MAX_NODES_CONFIG.get(code, 30)
                  final_nodes = merge_nodes(existing_nodes, new_nodes, max_nodes)

                  # ç”Ÿæˆé…ç½®æ–‡ä»¶
                  conf = make_config(final_nodes, code.upper())
                  with open(cfg["filename"], 'w', encoding='utf-8') as f:
                      yaml.dump(conf, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
                  print(f"{cfg['filename']} å·²æ›´æ–°")

          if __name__ == "__main__":
              main()
          EOF

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add sub_*.yaml
          git commit -m "Auto update nodes (HK:100, SG/JP:30) with mainland latency (ä¼˜è´¨èŠ‚ç‚¹<500ms) $(date +'%Y-%m-%d %H:%M:%S')" || exit 0
          git push
